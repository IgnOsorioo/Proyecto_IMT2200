{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa8bd5b",
   "metadata": {},
   "source": [
    "# Filtracion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b615efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456253ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función nos sirve para ir monitoreando los filtros\n",
    "def resumen_filtrado(df, len_original, texto=''):\n",
    "    len_nuevo = len(df)\n",
    "    eliminadas = len_original - len_nuevo\n",
    "    porcentaje = (len_nuevo / len_original) * 100 if len_original > 0 else 0\n",
    "    print(\"Filtrado: {:6d} → {:<6d} filas ({:6.2f}% mantenidas, {} eliminadas){}\".format(\n",
    "        len_original, len_nuevo, porcentaje, eliminadas,\n",
    "        f'   |   {texto}' if texto else ''\n",
    "    ))\n",
    "\n",
    "# Esta sirve para monitorear los cambios\n",
    "def resumen_cambios(df2, df1):\n",
    "    sentinel = object()\n",
    "    a = df1.astype(object).where(~df1.isna(), sentinel)\n",
    "    b = df2.astype(object).where(~df2.isna(), sentinel)\n",
    "\n",
    "    iguales_mask = (a == b).all(axis=1)\n",
    "    iguales = int(iguales_mask.sum())\n",
    "    total = len(df1)\n",
    "    diferentes = total - iguales\n",
    "    p = (iguales / total * 100) if total else 0.0\n",
    "\n",
    "    print(f\"Comparación de DataFrames ({total:6d} filas totales)\")\n",
    "    print(f\"Filas modificadas : {diferentes:6d}  ({100-p:6.2f}% distintas)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52786212",
   "metadata": {},
   "source": [
    "Nuestras bases de datos, tanto la de arriendos como la de ventas contienen 4 tablas.\n",
    "'principal', 'full_specs', 'full_specs_bin' son tablas con una columna que funciona como identificador de la propiedad llamada mlc, y el resto de las columnas son características de la propiedad. La cuarta tabla se llama 'grupos_bin' y simplemente dice a que tipo de grupo corresponde cada una de las características binarias de las propiedades. \n",
    "\n",
    "En la siguiente celda convertimos las 3 tablas que contienen información de las propiedades en DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ce91c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM principal': no such table: principal",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/sql.py:2664\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2663\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2664\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[31mOperationalError\u001b[39m: no such table: principal",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m tablas_nombres = (\u001b[33m'\u001b[39m\u001b[33mprincipal\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfull_specs\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfull_specs_bin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgrupos_bin\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m conn  = sqlite3.connect(db_path)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_p, df_fs, df_fsb, df_gb = [\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSELECT * FROM \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtab\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tab \u001b[38;5;129;01min\u001b[39;00m tablas_nombres]\n\u001b[32m      6\u001b[39m conn.close()\n\u001b[32m      9\u001b[39m last_len = \u001b[38;5;28mlen\u001b[39m(df_p)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/sql.py:528\u001b[39m, in \u001b[36mread_sql_query\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/sql.py:2728\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2717\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   2718\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2719\u001b[39m     sql,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2726\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2727\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m-> \u001b[39m\u001b[32m2728\u001b[39m     cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2729\u001b[39m     columns = [col_desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor.description]\n\u001b[32m   2731\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/sql.py:2676\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2673\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minner_exc\u001b[39;00m\n\u001b[32m   2675\u001b[39m ex = DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution failed on sql \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2676\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mDatabaseError\u001b[39m: Execution failed on sql 'SELECT * FROM principal': no such table: principal"
     ]
    }
   ],
   "source": [
    "db_path = \"database_venta.db\" # \"database_venta.db\"\n",
    "tablas_nombres = ('principal', 'full_specs', 'full_specs_bin', 'grupos_bin')\n",
    "\n",
    "conn  = sqlite3.connect(db_path)\n",
    "df_p, df_fs, df_fsb, df_gb = [pd.read_sql_query(f\"SELECT * FROM {tab}\", conn) for tab in tablas_nombres]\n",
    "conn.close()\n",
    "\n",
    "\n",
    "last_len = len(df_p)\n",
    "print(f'principal → {len(df_p)}, full_specs → {len(df_fs)}, full_specs_bin → {len(df_fsb)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41369768",
   "metadata": {},
   "source": [
    "# Filtrar DataFrame principal\n",
    "Acá vamos a hacer filtros que reducirán el dataframe principal. Hay que notar que este es el filtrado mas importante porque este datatrame no solo tiene los datos mas relevantes y mas fiables, sino que tambien es la única tabla donde si o si se encuentran el 100% de las propiedades. las otras tablas no necesariamente contienen todas las propiedades, pues puede haber algune aque no tenga definidas características binarias (por ende no tendrá ninguna fila en la tabla 'full_specs_bin') o puede ser que no se hayan scrapeado correctamente esos elementos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "****Filtro 1:**** Eliminar propiedades sin superficie total o sin baños o sin direcición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4fb52a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado: 104545 → 100483 filas ( 96.11% mantenidas, 4062 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_p1 = df_p.dropna(subset=[\"Superficie total\", \"Superficie total unidad\", \"Baños\", \"Dirección\"])\n",
    "resumen_filtrado(df_p1, len(df_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ceb0c7",
   "metadata": {},
   "source": [
    "****Filtro  2:**** Eliminar propiedades con mas de el dobre de baños que de dormitorios (sin dormitorios se reemplaza por 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "32672a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado: 100483 → 99881  filas ( 99.40% mantenidas, 602 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_p2 = df_p1[df_p1[\"Baños\"] < 2 * df_p1[\"Dormitorios\"].fillna(1)]\n",
    "resumen_filtrado(df_p2, len(df_p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784fca4d",
   "metadata": {},
   "source": [
    "****Filtro 3:**** Esto realmente no es un filtro. Lo que hacemos es reemplazar dormitorios nulos por 0 dormitorios. No se hizo antes para usar el .fillna(1) en el filtro 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "65e116a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de DataFrames ( 99881 filas totales)\n",
      "Filas modificadas :    246  (  0.25% distintas)\n"
     ]
    }
   ],
   "source": [
    "df_p3 = df_p2.copy()\n",
    "df_p3[\"Dormitorios\"] = df_p3[\"Dormitorios\"].fillna(0)\n",
    "resumen_cambios(df_p3, df_p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c56d8",
   "metadata": {},
   "source": [
    "****Filtro 4:**** Eliminamos cuando no hay dormitorio y no es departamento. Así filtramos ventas de terreno o arriendos de locales comerciales mal indexados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "912aad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  99881 → 99846  filas ( 99.96% mantenidas, 35 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_p4 = df_p3[~((df_p3[\"Dormitorios\"] == 0) & (df_p3['inmueble'] != 'departamento'))]\n",
    "resumen_filtrado(df_p4, len(df_p3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9cb924",
   "metadata": {},
   "source": [
    "****Filtro 5:**** Elimina propiedades cuya superficie está medida en hectareas y es de mas de 50ha (eso ya no es una parcela, es una venta de terrenos mal indexada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d8609e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  99846 → 99796  filas ( 99.95% mantenidas, 50 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_p5 = df_p4[~( (df_p4[\"Superficie total unidad\"] == 'ha') & (df_p4[\"Superficie total\"] > 50))]\n",
    "resumen_filtrado(df_p5, len(df_p4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f3555",
   "metadata": {},
   "source": [
    "****Filtro 6:**** Eliminamos propiedades de mas de 10 habitaciones o de mas de 10 baños, pues seguramente son edificios compretos o casas con finalidad comercial u hotelera mal indexadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fbcedf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  99796 → 99293  filas ( 99.50% mantenidas, 503 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_p6 = df_p5[(df_p5[\"Dormitorios\"].fillna(0) < 10) & (df_p5[\"Baños\"].fillna(0) < 10)]\n",
    "resumen_filtrado(df_p6, len(df_p5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4388de6",
   "metadata": {},
   "source": [
    "****Filtro 7:**** Este filtro elimina los elementos que no contienen precio ni en pesos ni en uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aed2fc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  99293 → 99293  filas (100.00% mantenidas, 0 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_p7 = df_p6[df_p6[\"$\"].notna() | df_p6[\"UF\"].notna()]\n",
    "resumen_filtrado(df_p7, len(df_p6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94974d5",
   "metadata": {},
   "source": [
    "****Filtro 8:**** Eliminamos las que tienen precio en US$ (suelen ser propiedades de fuera de chile mal catalogadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "652811f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  99293 → 99284  filas ( 99.99% mantenidas, 9 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_p8 = df_p7[df_p7[\"US$\"].isna()]\n",
    "resumen_filtrado(df_p8, len(df_p7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e5554",
   "metadata": {},
   "source": [
    "****Filtro 9:**** Acá completamos los precios, pues algunas propiedades tienen el precio en Uf's pero no en pesos chilenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ef945b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de DataFrames ( 99284 filas totales)\n",
      "Filas modificadas :      0  (  0.00% distintas)\n"
     ]
    }
   ],
   "source": [
    "uf_cpl = 39541.62\n",
    "\n",
    "df_p9 = df_p8.copy()\n",
    "df_p9.loc[df_p9[\"$\"].isna() & df_p9[\"UF\"].notna(), \"$\"] = (df_p9.loc[df_p9[\"$\"].isna() & df_p9[\"UF\"].notna(), \"UF\"] * uf_cpl)\n",
    "resumen_cambios(df_p9, df_p8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7433430c",
   "metadata": {},
   "source": [
    "****Filtro 10:**** Eliminamos cuando los gastos comunes son mayores al valor de la propiedad (ya sea arriendo o venta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bafa1dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  99284 → 99270  filas ( 99.99% mantenidas, 14 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_p10 = df_p9[df_p9[\"gastos_comunes\"].fillna(0) <= df_p9[\"$\"].fillna(0)]\n",
    "resumen_filtrado(df_p10, len(df_p9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad42c58",
   "metadata": {},
   "source": [
    "****Filtro 11:**** Eliminamos cuando los valores son muy baratos o muy caros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ad293305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  99270 → 99270  filas (100.00% mantenidas, 0 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "M = 1e6\n",
    "if 'venta' in db_path:\n",
    "    df_p11 = df_p10[(21*M <= df_p10['$']) & df_p10['$'] <= 6000*M]\n",
    "elif 'arriendo' in db_path:\n",
    "    df_p11 = df_p10[\n",
    "        (df_p10['$'] >= 100000) &\n",
    "        ~( (df_p10['$'] > 10*M) & (df_p10['inmueble'] == 'departamento') ) &\n",
    "        (df_p10['$'] <= 30*M)\n",
    "    ]\n",
    "resumen_filtrado(df_p11, len(df_p10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c6fc56",
   "metadata": {},
   "source": [
    "****Filtro 12:**** Evitar venta de terrenos y de promesas de compra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "389ad235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  99270 → 99020  filas ( 99.75% mantenidas, 250 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_p12 = df_p11.copy()\n",
    "for frase in {\n",
    "    'Se vende terreno', 'Se vende terreno'.lower(), 'Se vende terreno'.upper(),\n",
    "    'promesa de compra', 'promesa compra', 'Promesa Compra'\n",
    "}:\n",
    "    df_p12 = df_p12[~df_p12['titulo'].str.contains(frase, case=False, na=False)]\n",
    "    df_p12 = df_p12[~df_p12['Descripción'].str.contains(frase, case=False, na=False)]\n",
    "resumen_filtrado(df_p12, len(df_p11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ffde7a",
   "metadata": {},
   "source": [
    "****Filtro 13 (Exclusivo arriendos):**** Muchas veces, en especial en departamentos con arriendos bajo los $800.000, sucede que se promociona un precio, pero en la descripción pone que despues del segundo mes, este aumenta considerablemente (al rededor de un 100%). Para solucionar esto, se buscan distintos precios en la descripción, y en caso de que este estre entre 1.5 y 2.5 del precio publicado y sea menor al millón de pesos, se procede a evaluar si la descripción contiene la palabra garantía (para evitar confundir garantia con precio real). En caso de que pase todos estos filtros *una sola vez*, se procede a actualizar el valor real del arriendo. En caso de que pase los filtros *mas de 2 veces* se procede a eliminar esa fila del dataframe, pues no es confiable el precio y puede dañar las estadísticas.\n",
    "\n",
    "Como se puede observar este filtro no es perfecto y lo iremos perfeccionando, pero lo revisamos exaustivamente printeando links y comparando y llegamos a la conclusión de que no genera falsos positivos, por lo que en un futuro lo iremos mejorando para que cada vez mas precios se reflejen correctamente en la estadística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "138526b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de DataFrames ( 99020 filas totales)\n",
      "Filas modificadas :      0  (  0.00% distintas)\n",
      "----------------------------\n",
      "Filtrado:  99020 → 99020  filas (100.00% mantenidas, 0 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "def extraer_precios(texto):\n",
    "        if not isinstance(texto, str): return []\n",
    "        patron = r'\\$?\\s*(?:\\d{1,3}(?:\\.\\d{3})+|\\d{6,})\\b'\n",
    "\n",
    "        # Esto es una lista de strings\n",
    "        coincidencias = re.findall(patron, texto) \n",
    "\n",
    "        # Esto lo convierte en una lista de int's\n",
    "        precios = [int(re.sub(r'[^\\d]', '', c)) for c in coincidencias]\n",
    "\n",
    "        # esto elimina numeros de telefono\n",
    "        precios = [p for p in precios if len(str(p)) < 8]\n",
    "        return precios\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_p13 = df_p12.copy()\n",
    "del_idx = set()\n",
    "\n",
    "if 'arriendo' in db_path:\n",
    "    for i, fila in df_p13.iterrows():\n",
    "        contador, numero_ = 0, None\n",
    "        for numero in extraer_precios(fila['Descripción']):\n",
    "            if 1.5 * fila['$'] < numero < 2.5 * fila['$'] and numero < 1e6:\n",
    "                if not any([text in fila['Descripción'] for text in (\n",
    "                    'Garantía', 'Garantia', 'garantía', 'garantia'\n",
    "                )]):\n",
    "                    contador += 1\n",
    "                    numero_ = numero\n",
    "            \n",
    "        if contador == 1:\n",
    "            df_p13.at[i, '$'] = numero_\n",
    "        elif contador > 1:\n",
    "            del_idx.add(i)\n",
    "    \n",
    "    \n",
    "\n",
    "resumen_cambios(df_p13, df_p12)\n",
    "print('----------------------------')\n",
    "df_p13 = df_p13.drop(index=del_idx)\n",
    "resumen_filtrado(df_p13, len(df_p12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdaf694",
   "metadata": {},
   "source": [
    "# Filtros de DataFrame full_specs\n",
    "\n",
    "Este Dataframe contiene información mas completa sobre las propiedades, pero es ligeramente meos fiable. No necesariamente todas las propiedades tienen características full_specs, aunque la gran mayoría si.\n",
    "\n",
    "Cabe destacar que si una propiedad Es filtrada en los filtros de principal, este filtro es tan inportante que amerita eliminar esa propiedad de la base de datos. Sin embargo, como los datos de full_specs tienen menos fiabilidad, muchas veces que los datos sean inconsistentes no implica que toda la propiedad lo sea, por lo que si se elimina la propiedad del dataframe full_specs, pero no de principal, y simpelmente se excluye esa propiedad en los analisis de variables que se encuentren en full_specs.\n",
    "\n",
    "****Filtro 1:**** Iniciamos eliminando todas las filas cuyo mlc no se encuentra en principal, pues de ser así significa que esta propiedad fue filtrada antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "73b80585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado: 104178 → 99009  filas ( 95.04% mantenidas, 5169 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_fs1 = df_fs[df_fs['mlc'].isin(df_p13['mlc'])]\n",
    "resumen_filtrado(df_fs1, len(df_fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1015e1ca",
   "metadata": {},
   "source": [
    "****Filtro 2:**** Acá eliminamos las filas donde haya inconsistencias en las medidas de la superficie.\n",
    "1. total >= util\n",
    "2. total >= terraza\n",
    "3. total * gap >= util + terraza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "53f5700b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  99009 → 96604  filas ( 97.57% mantenidas, 2405 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "# ! Filtro superficie\n",
    "unidad, gap = {'m²': 1, 'ha': 10000, 0: 0}, 1\n",
    "col1,  col2,  col3  = \"Superficie total\", \"Superficie útil\", \"Superficie de terraza\"\n",
    "col1_, col2_, col3_ = [df_fs1[col + ' unidad'].map(unidad).fillna(0) for col in (col1, col2, col3)]\n",
    "\n",
    "df_fs2 = df_fs1[\n",
    "    (df_fs1[col1].fillna(0) * col1_             >= df_fs1[col2].fillna(0) * col2_) &\n",
    "    (df_fs1[col1].fillna(0) * col1_             >= df_fs1[col3].fillna(0) * col3_) &\n",
    "    (df_fs1[col1].fillna(0) * col1_ * (1 + gap) >= df_fs1[col2].fillna(0) * col2_ + df_fs1[col3].fillna(0) * col3_)\n",
    "]\n",
    "resumen_filtrado(df_fs2, len(df_fs1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645be282",
   "metadata": {},
   "source": [
    "****Filtro 3:**** Superficie util irreal (de las de 10.000 m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "19d8d3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  96604 → 96498  filas ( 99.89% mantenidas, 106 eliminadas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\AppData\\Local\\Temp\\ipykernel_23276\\4009217669.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_fs3 = df_fs2[df_fs2[col2].fillna(0) * col2_ <= 1e4]\n"
     ]
    }
   ],
   "source": [
    "df_fs3 = df_fs2[df_fs2[col2].fillna(0) * col2_ <= 1e4] \n",
    "resumen_filtrado(df_fs3, len(df_fs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4f186",
   "metadata": {},
   "source": [
    "****Filtro 4:**** Quitar gastos comunes en uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d1a45b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  96498 → 95477  filas ( 98.94% mantenidas, 1021 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_fs4 = df_fs3[df_fs3['Gastos comunes unidad'].fillna(0) != 'UF'] \n",
    "resumen_filtrado(df_fs4, len(df_fs3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae66cb",
   "metadata": {},
   "source": [
    "****Filtro 5:**** Quitar departamentos con mas de 5 estacionamientos.\n",
    "\n",
    "****NOTA:**** Los otros filtros que hemos hecho en full_specs son filtros que implican desorden en los datos entregados en full_specs, pero no desorden en los datos generales de la propiedad. Sin embargo, que haya departamentos con mas de 5 estacionamientos si implica que la propiedad puede estar viciada perse, por lo que en este filtro eliminamos la propiedad tanto de principal como de full_specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee8885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtro en full_specs\n",
      "Filtrado:  95477 → 95234  filas ( 99.75% mantenidas, 243 eliminadas)\n",
      "---------------\n",
      "Filtro en principal\n",
      "Filtrado:  99020 → 98777  filas ( 99.75% mantenidas, 243 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "del_idx, del_mlc = set(), set()\n",
    "for i, fila in df_fs4.iterrows():\n",
    "    if df_p13.loc[df_p13[\"mlc\"] == fila['mlc'], \"inmueble\"].item() == 'departamento' \\\n",
    "        and 6 <= fila['Estacionamientos']:\n",
    "        del_idx.add(i), del_mlc.add(fila['mlc'])\n",
    "\n",
    "df_fs5 = df_fs4.drop(index=del_idx)\n",
    "df_p14 = df_p13[~df_p13['mlc'].isin(del_mlc)]\n",
    "\n",
    "print('Filtro en full_specs')\n",
    "resumen_filtrado(df_fs5, len(df_fs4))\n",
    "print('---------------')\n",
    "print('Filtro en principal')\n",
    "resumen_filtrado(df_p14, len(df_p13))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16882a",
   "metadata": {},
   "source": [
    "# Filtros DataFrame full_specs_bin\n",
    "Este dataframe contiene características binarias de las propiedades. No solo no todas las propiedades tienen características binarias, sino que estas son las características de menor calidad que tenemos. Por ende, al mínimo descuadre entre ellas, no hay que dudar en eliminar todas, pues puede corromper los análisis estadísticos.\n",
    "\n",
    "\n",
    "****Filtro 1:**** Eliminamos todos los mlc que no se encuentran en full_specs, y por ende, tampoco en principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b523d6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado:  93151 → 87224  filas ( 93.64% mantenidas, 5927 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "df_fsb1 = df_fsb[df_fsb['mlc'].isin(df_fs5['mlc'])]\n",
    "resumen_filtrado(df_fsb1, len(df_fsb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60773e82",
   "metadata": {},
   "source": [
    "****Filtro 2:**** Este filtro elimina propiedades cuyas características binarias no sean consistentes lógicamente segun premisas que hemos generado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01cc1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de cada uno de los filtros lógicos agregados\n",
      "---------------------------\n",
      "Filtrado:  87224 → 84524  filas ( 96.90% mantenidas, 2700 eliminadas)   |   Recepción -> Conserjería\n",
      "Filtrado:  84524 → 84288  filas ( 99.72% mantenidas, 236 eliminadas)   |   Cisterna -> Agua corriente\n",
      "Filtrado:  84288 → 84124  filas ( 99.81% mantenidas, 164 eliminadas)   |   Refrigerador -> Cocina \n",
      "Filtrado:  84124 → 80860  filas ( 96.12% mantenidas, 3264 eliminadas)   |   Walk-in clóset -> Closets\n",
      "Filtrado:  80860 → 75102  filas ( 92.88% mantenidas, 5758 eliminadas)   |   Baño de visitas -> Living    \n",
      "Filtrado:  75102 → 75102  filas (100.00% mantenidas, 0 eliminadas)   |   Uso comercial -> ¬Solo familia\n",
      "Filtrado:  75102 → 75102  filas (100.00% mantenidas, 0 eliminadas)   |   Solo familias -> ¬Uso comercial\n",
      "Filtrado:  75102 → 70468  filas ( 93.83% mantenidas, 4634 eliminadas)   |   Jardín -> (Patio v Con área verde)\n",
      "---------------------------\n",
      "Resumen acumulado de todos los filtros lógicos aplicados\n",
      "---------------------------\n",
      "Filtrado:  87224 → 70468  filas ( 80.79% mantenidas, 16756 eliminadas)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Recepción       -> Conserjería    | Si no tiene recepción ¿Como va a tener conserjería?\n",
    "Cisterna        -> Agua corriente | Sin cisterna no se puede tener agua corriente\n",
    "Refrigerador    -> Cocina         | Ya es raro que un inmueble no tenga cocina,\n",
    "                                  | pero si tiene refigeraror ya es de locos que no tenga cocina\n",
    "Walk-in clóset  -> Closets        | Por definición un walk-in closen es un closet\n",
    "Baño de visitas -> Living         | \n",
    "Uso comercial   -> ¬Solo familias | Si el uso en comercial no puede ser solo_familias\n",
    "Solo familias   -> ¬Uso comercial | y viceversa\n",
    "Jardín          -> (Patio v Con área verde) | un jardin no puede no estar en el patio (sino es un macetero)\n",
    "                                              y  además, es un area verde por si mismo.\n",
    "\"\"\"\n",
    "\n",
    "df_fsb21 = df_fsb1[(df_fsb1[\"Recepción\"]         != 1) | (df_fsb1[\"Conserjería\"]     != 0)] if {\"Recepción\", \"Conserjería\"      }.issubset(df_fsb1.columns ) else df_fsb1\n",
    "df_fsb22 = df_fsb21[(df_fsb21[\"Cisterna\"]        != 1) | (df_fsb21[\"Agua corriente\"] != 0)] if {\"Cisterna\", \"Agua corriente\"    }.issubset(df_fsb21.columns) else df_fsb21\n",
    "df_fsb23 = df_fsb22[(df_fsb22[\"Refrigerador\"]    != 1) | (df_fsb22[\"Cocina\"]         != 0)] if {\"Refrigerador\", \"Cocina\"        }.issubset(df_fsb22.columns) else df_fsb22\n",
    "df_fsb24 = df_fsb23[(df_fsb23[\"Walk-in clóset\"]  != 1) | (df_fsb23[\"Closets\"]        != 0)] if {\"Walk-in clóset\", \"Closets\"     }.issubset(df_fsb23.columns) else df_fsb23\n",
    "df_fsb25 = df_fsb24[(df_fsb24[\"Baño de visitas\"] != 1) | (df_fsb24[\"Living\"]         != 0)] if {\"Baño de visitas\", \"Living\"     }.issubset(df_fsb24.columns) else df_fsb24\n",
    "df_fsb26 = df_fsb25[(df_fsb25[\"Uso comercial\"]   != 1) | (df_fsb25[\"Solo familias\"]  != 1)] if {\"Uso comercial\", \"Solo familias\"}.issubset(df_fsb25.columns) else df_fsb25\n",
    "df_fsb27 = df_fsb26[(df_fsb26[\"Solo familias\"]   != 1) | (df_fsb26[\"Uso comercial\"]  != 1)] if {\"Uso comercial\", \"Solo familias\"}.issubset(df_fsb26.columns) else df_fsb26\n",
    "df_fsb2  = df_fsb27[(df_fsb27[\"Jardín\"]          != 1) | (df_fsb27[\"Patio\"]          != 0) | (df_fsb27[\"Con área verde\"] != 0)] if {\"Jardín\", \"Patio\", \"Con área verde\"}.issubset(df_fsb27.columns) else df_fsb27\n",
    "\n",
    "\n",
    "print('Resumen de cada uno de los filtros lógicos agregados')\n",
    "print('---------------------------')\n",
    "resumen_filtrado(df_fsb21, len(df_fsb1), 'Recepción -> Conserjería')\n",
    "resumen_filtrado(df_fsb22, len(df_fsb21), 'Cisterna -> Agua corriente')\n",
    "resumen_filtrado(df_fsb23, len(df_fsb22), 'Refrigerador -> Cocina ')\n",
    "resumen_filtrado(df_fsb24, len(df_fsb23), 'Walk-in clóset -> Closets')\n",
    "resumen_filtrado(df_fsb25, len(df_fsb24), 'Baño de visitas -> Living    ')\n",
    "resumen_filtrado(df_fsb26, len(df_fsb25), 'Uso comercial -> ¬Solo familia')\n",
    "resumen_filtrado(df_fsb27, len(df_fsb26), 'Solo familias -> ¬Uso comercial')\n",
    "resumen_filtrado(df_fsb2, len(df_fsb27), 'Jardín -> (Patio v Con área verde)')\n",
    "print('---------------------------')\n",
    "print('Resumen acumulado de todos los filtros lógicos aplicados')\n",
    "print('---------------------------')\n",
    "resumen_filtrado(df_fsb2, len(df_fsb1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b86d4ea",
   "metadata": {},
   "source": [
    "# Guardar base de datos filtrada\n",
    "\n",
    "Ahora convetiremos estos dataframes en una base de datos .db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87205ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m db_path_clean = \u001b[43mdb_path\u001b[49m[:-\u001b[32m3\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m_clean.db\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      3\u001b[39m dfs = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprincipal\u001b[39m\u001b[33m\"\u001b[39m: df_p,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfull_specs\u001b[39m\u001b[33m\"\u001b[39m: df_fs,\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfull_specs_bin\u001b[39m\u001b[33m\"\u001b[39m: df_fsb,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgrupos_bin\u001b[39m\u001b[33m\"\u001b[39m: df_gb,\n\u001b[32m      8\u001b[39m }\n\u001b[32m     11\u001b[39m con = sqlite3.connect(db_path_clean)\n",
      "\u001b[31mNameError\u001b[39m: name 'db_path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "db_path_clean = db_path[:-3] + '_clean.db'\n",
    "\n",
    "dfs = {\n",
    "    \"principal\": df_p,\n",
    "    \"full_specs\": df_fs,\n",
    "    \"full_specs_bin\": df_fsb,\n",
    "    \"grupos_bin\": df_gb,\n",
    "}\n",
    "\n",
    "\n",
    "con = sqlite3.connect(db_path_clean)\n",
    "for table, df in dfs.items():\n",
    "    df.to_sql(table, con, if_exists=\"replace\", index=False)\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
